{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from NeuralNetwork import NeuralNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build an AND dataset\n",
    "dataset = []\n",
    "for i in range(1000):\n",
    "    vals = [random.randint(0,1), random.randint(0,1)]\n",
    "    dataset.append([vals[0], vals[1], [vals[0] and vals[1]]])\n",
    "\n",
    "n = NeuralNetwork(2, 5, 1)\n",
    "n.train(dataset, n_epoch=100)\n",
    "\n",
    "#Test that the network represents an AND gate\n",
    "assert(round(n.predict([0,0])[0]) == 0)\n",
    "assert(round(n.predict([1,0])[0]) == 0)\n",
    "assert(round(n.predict([0,1])[0]) == 0)\n",
    "assert(round(n.predict([1,1])[0]) == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-d854789cb65e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNeuralNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_hidden_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#Test that the network represents an XOR gate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/random-notebooks/NeuralNetwork.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, rows, n_epoch, print_epoch)\u001b[0m\n\u001b[1;32m    114\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0msum_error\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomputeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mback_propagate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Check that this should be inputs passed in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/random-notebooks/NeuralNetwork.py\u001b[0m in \u001b[0;36mback_propagate\u001b[0;34m(self, target)\u001b[0m\n\u001b[1;32m     83\u001b[0m                 \u001b[0mneuron\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneurons\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mneuron_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0mneuron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mnext_neuron_i\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneurons\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m                     \u001b[0mnext_neuron\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneurons\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnext_neuron_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                     \u001b[0mneuron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnext_neuron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelta\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnext_neuron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mneuron_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Build an XOR gate dataset, with 4 hidden layer!!!\n",
    "dataset = []\n",
    "for i in range(1000):\n",
    "    vals = [random.randint(0,1), random.randint(0,1)]\n",
    "    dataset.append([vals[0], vals[1], [(not (vals[0] and vals[1])) and (vals[0] or vals[1])]])\n",
    "\n",
    "n = NeuralNetwork(2, 5, 1, n_hidden_layers=4)\n",
    "n.train(dataset, n_epoch=2000)\n",
    "\n",
    "#Test that the network represents an XOR gate\n",
    "assert(round(n.predict([0,0])[0]) == 0)\n",
    "assert(round(n.predict([1,0])[0]) == 1)\n",
    "assert(round(n.predict([0,1])[0]) == 1)\n",
    "assert(round(n.predict([1,1])[0]) == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build an AND dataset\n",
    "dataset = []\n",
    "for i in range(1000):\n",
    "    vals = [random.randint(0,1), random.randint(0,1), random.randint(0,1), random.randint(0,1)]\n",
    "    dataset.append([vals[0], vals[1], vals[2], vals[3], [vals[0] and vals[1] and vals[2] and vals[3]]])\n",
    "\n",
    "n = NeuralNetwork(4, 5, 1)\n",
    "n.train(dataset, n_epoch=100)\n",
    "\n",
    "#Test that the network represents an AND gate\n",
    "assert(round(n.predict([0,0,0,0])[0]) == 0)\n",
    "assert(round(n.predict([0,0,0,1])[0]) == 0)\n",
    "assert(round(n.predict([0,0,1,0])[0]) == 0)\n",
    "assert(round(n.predict([0,0,1,1])[0]) == 0)\n",
    "assert(round(n.predict([0,1,0,0])[0]) == 0)\n",
    "assert(round(n.predict([0,1,0,1])[0]) == 0)\n",
    "assert(round(n.predict([0,1,1,0])[0]) == 0)\n",
    "assert(round(n.predict([0,1,1,1])[0]) == 0)\n",
    "assert(round(n.predict([1,0,0,0])[0]) == 0)\n",
    "assert(round(n.predict([1,0,0,1])[0]) == 0)\n",
    "assert(round(n.predict([1,0,1,0])[0]) == 0)\n",
    "assert(round(n.predict([1,0,1,1])[0]) == 0)\n",
    "assert(round(n.predict([1,1,0,0])[0]) == 0)\n",
    "assert(round(n.predict([1,1,0,1])[0]) == 0)\n",
    "assert(round(n.predict([1,1,1,0])[0]) == 0)\n",
    "assert(round(n.predict([1,1,1,1])[0]) == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build an SumToOne dataset\n",
    "dataset = []\n",
    "for i in range(1000):\n",
    "    vals = [random.random(), random.random(), ]\n",
    "    dataset.append([vals[0], vals[1], [(vals[0]+vals[1]) >= 1.0]])\n",
    "\n",
    "n = NeuralNetwork(2, 10, 1)\n",
    "n.train(dataset, n_epoch=200)\n",
    "\n",
    "#Test that the network represents a SumToOne gate\n",
    "print(\"Should be lower than 0.5\")\n",
    "print(n.predict([0.3, 0.4]))\n",
    "print(n.predict([0.1, 0.2]))\n",
    "print(n.predict([0.45, 0.45]))\n",
    "print(n.predict([0.49, 0.49]))\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "print(\"Should be higher than 0.5\")\n",
    "print(n.predict([0.3, 1.0]))\n",
    "print(n.predict([0.6, 0.5]))\n",
    "print(n.predict([0.50, 0.50]))\n",
    "#it's so close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if it's classification maybe I should just round things to bind them into groups???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-7f0c6229ab33>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNeuralNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_hidden_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#, print_epoch=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#Test that the network represents an AND gate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/random-notebooks/NeuralNetwork.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, rows, n_epoch, print_epoch)\u001b[0m\n\u001b[1;32m    112\u001b[0m                 \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m                 \u001b[0msum_error\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomputeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mback_propagate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/random-notebooks/NeuralNetwork.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetOutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/random-notebooks/NeuralNetwork.py\u001b[0m in \u001b[0;36mgetOutput\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgetOutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mneuron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetOutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mneuron\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneurons\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcomputeOutputError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/random-notebooks/NeuralNetwork.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgetOutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mneuron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetOutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mneuron\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneurons\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcomputeOutputError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/random-notebooks/NeuralNetwork.py\u001b[0m in \u001b[0;36mgetOutput\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m###assert(len(inputs) == self.input_count)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mweighted_input_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweighted_input_sum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/random-notebooks/NeuralNetwork.py\u001b[0m in \u001b[0;36msigmoid\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#A few helper functions representing a common activation function and its derivative\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msigmoid_derivative\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Build an AND dataset\n",
    "random.seed(1)\n",
    "dataset = []\n",
    "for i in range(1000):\n",
    "    vals = [random.randint(0,1), random.randint(0,1), random.randint(0,1), random.randint(0,1)]\n",
    "    dataset.append([vals[0], vals[1], vals[2], vals[3], [vals[0] and vals[1] and vals[2] and vals[3]]])\n",
    "\n",
    "    \n",
    "n = NeuralNetwork(4, 5, 1, n_hidden_layers=4)\n",
    "n.train(dataset, n_epoch=2000) #, print_epoch=True)\n",
    "\n",
    "#Test that the network represents an AND gate\n",
    "assert(round(n.predict([0,0,0,0])[0]) == 0)\n",
    "assert(round(n.predict([0,0,0,1])[0]) == 0)\n",
    "assert(round(n.predict([0,0,1,0])[0]) == 0)\n",
    "assert(round(n.predict([0,0,1,1])[0]) == 0)\n",
    "assert(round(n.predict([0,1,0,0])[0]) == 0)\n",
    "assert(round(n.predict([0,1,0,1])[0]) == 0)\n",
    "assert(round(n.predict([0,1,1,0])[0]) == 0)\n",
    "assert(round(n.predict([0,1,1,1])[0]) == 0)\n",
    "assert(round(n.predict([1,0,0,0])[0]) == 0)\n",
    "assert(round(n.predict([1,0,0,1])[0]) == 0)\n",
    "assert(round(n.predict([1,0,1,0])[0]) == 0)\n",
    "assert(round(n.predict([1,0,1,1])[0]) == 0)\n",
    "assert(round(n.predict([1,1,0,0])[0]) == 0)\n",
    "assert(round(n.predict([1,1,0,1])[0]) == 0)\n",
    "assert(round(n.predict([1,1,1,0])[0]) == 0)\n",
    "assert(round(n.predict([1,1,1,1])[0]) == 1)\n",
    "\n",
    "print(n.predict([0,0,0,0])[0])\n",
    "print(n.predict([0,0,0,1])[0])\n",
    "print(n.predict([0,0,1,1])[0])\n",
    "print(n.predict([0,1,0,0])[0])\n",
    "print(n.predict([0,1,0,1])[0])\n",
    "print(n.predict([0,1,1,0])[0])\n",
    "print(n.predict([0,1,1,1])[0])\n",
    "print(n.predict([1,0,0,0])[0])\n",
    "print(n.predict([1,0,0,1])[0])\n",
    "print(n.predict([1,0,1,0])[0])\n",
    "print(n.predict([1,0,1,1])[0])\n",
    "print(n.predict([1,1,0,0])[0])\n",
    "print(n.predict([1,1,0,1])[0])\n",
    "print(n.predict([1,1,1,0])[0])\n",
    "print(n.predict([1,1,1,1])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example link - https://matthewmazur.files.wordpress.com/2018/03/neural_network-9.png\n",
    "#https://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/\n",
    "n2 = NeuralNetwork(2, 2, 2)\n",
    "n2.layers[0].neurons[0].weights = [.15, .20]\n",
    "n2.layers[0].neurons[1].weights = [.25, .30]\n",
    "n2.layers[1].neurons[0].weights = [.40, .45]\n",
    "n2.layers[1].neurons[1].weights = [.50, .55]\n",
    "n2.layers[0].neurons[0].bias = 0.35\n",
    "n2.layers[0].neurons[1].bias = 0.35\n",
    "n2.layers[1].neurons[0].bias = 0.60\n",
    "n2.layers[1].neurons[1].bias = 0.60\n",
    "\n",
    "n2.predict([0.05, 0.10])\n",
    "print(n2.layers[1].neurons[0].output, \"==\", 0.751)\n",
    "print(n2.layers[1].neurons[1].output, \"==\", 0.772)\n",
    "\n",
    "print(sigmoid_derivative(n2.layers[1].neurons[0].output), \"==\", 0.1868)\n",
    "\n",
    "n2.back_propagate([0.01, 0.99])\n",
    "hidden_layer = n2.layers[0]\n",
    "print(hidden_layer.neurons[0].weights)\n",
    "print(hidden_layer.neurons[1].weights)\n",
    "output_layer = n2.layers[1]\n",
    "print(output_layer.neurons[0].weights)\n",
    "print(output_layer.neurons[1].weights)\n",
    "\n",
    "n2.update_weights([0.05, 0.10])\n",
    "\n",
    "hidden_layer = n2.layers[0]\n",
    "print(hidden_layer.neurons[0].weights)\n",
    "print(hidden_layer.neurons[0].bias)\n",
    "print(hidden_layer.neurons[1].weights)\n",
    "print(hidden_layer.neurons[1].bias)\n",
    "output_layer = n2.layers[1]\n",
    "print(output_layer.neurons[0].weights)\n",
    "print(output_layer.neurons[0].bias)\n",
    "print(output_layer.neurons[1].weights)\n",
    "print(output_layer.neurons[1].bias)\n",
    "\n",
    "print(n2.layers[1].neurons[0].weights[0], \"== 0.408666186\")\n",
    "print(n2.layers[1].neurons[0].weights[1], \"== 0.511301270\")\n",
    "print(n2.layers[1].neurons[0].bias, \"== 0.561370121\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Maybe the deeper the number of layers the more training that is needed\n",
    "#Weights are not constrained to be positive or even -1.0 to 1.0 they can be any number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
