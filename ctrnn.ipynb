{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ctrnn implemented and modeled as a system of ordinary differential equations, with neuron potentials as the dependent variables.\n",
    "\n",
    "The time evolution of the network is computed using the forward Euler method:\n",
    "\n",
    "Recurrent means that there are cycles in the neurons. This can be the output being used as an input at the next time step or... A->B and B->A coming back around."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#make pyplot text white\n",
    "params = {\"ytick.color\" : \"b\",\n",
    "          \"xtick.color\" : \"b\",\n",
    "          \"axes.labelcolor\" : \"b\",\n",
    "          \"axes.edgecolor\" : \"b\"}\n",
    "plt.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A few helper functions representing a common activation function and its derivative\n",
    "def sigmoid(x):\n",
    "    if abs(x) > 100:\n",
    "        print(x)\n",
    "    return 1/(1 + math.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(s):\n",
    "    return s * (1.0 - s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's actually a term \"activation potential\" that is value plugged into the actiavation function\n",
    "1. If one does not want to ignore temporal summation, the sum of weighted inputs is used to drive a leaky RC tank circuit.\n",
    "2. The output of that tank device is passed to the output/transfer function\n",
    "3. https://en.wikipedia.org/wiki/Leaky_integrator\n",
    "4. y is apparently the \"activation_potential\" referred to as both activation and potential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Leaky Integrator</h2>\n",
    "<a href=\"https://en.wikipedia.org/wiki/Leaky_integrator\">link</a>\n",
    "<p>\n",
    "    $\\frac{dx}{dt} = -Ax + C$<br>\n",
    "    where $A$ is a rate of 'leak' aka a time constant<br>\n",
    "    where $C$ is the input<br>\n",
    "    This gives the derivative<br>\n",
    "    The derivative is useful because it gives the slope for a given point and therefore allows you to compute the next value<br>\n",
    "</p>\n",
    "<hr>\n",
    "\n",
    "<h2>Applications of \"Leaky Integrator\" to Recursive Neurons</h2>\n",
    "<p>\n",
    "    $\\frac{dx}{dt} = -Ax + C$<br>\n",
    "    $\\frac{da(x)}{dt} = -(1/\\tau) * a(x) + \\sum^{N}_{i=1}{w_{ij}x_j(t)}$<br>\n",
    "    $-1/\\tau$ is the rate of 'leak'<br>\n",
    "    $a$ is the function to be derived<br>\n",
    "    $\\sum^{N}_{j=1}{w_{ij}x_j(t)}$ where j is the index of neurons from the previous layer, is the inputs for neuron i aka the \"weighted input sum\"\n",
    "</p>\n",
    "<hr>\n",
    "\n",
    "<h2>Euler's Forward Method</h2>\n",
    "<a href=\"http://fourier.eng.hmc.edu/e176/lectures/ch5/node3.html\">link</a>\n",
    "<p>\n",
    "    This is an application of \"Forward Euler's Method\"<br>\n",
    "    \"Forward Euler's Method\" finds the value of y after a given amount of time by taking steps along its slope<br>\n",
    "    use derivative $y`(t)$ at the beginning of the interval $[t,t+h]$ to approximate $\\Delta y = hy`(t)$<br>\n",
    "    $y(t+h) ~= y(t) + hy`(t)$ where h is the size of the time step<br>\n",
    "    This gives you an approximation of the value y at time t+h, but this value will only be accurate for smaller values of h<br>\n",
    "    Therefore it is good practice to use \"Euler's Forward Method\" for multiple iterations for small values of h if you want to find y for a larger time into the future.\n",
    "</p>\n",
    "<hr>\n",
    "\n",
    "<h2>Applying Euler's Forward Method to \"Leaky Integrator\" of Recursive Neuron</h2>\n",
    "<p>\n",
    "    $\\frac{da(t)}{dt} = -(1/\\tau) * a(t) + \\sum^{N}_{i=1}{w_{ij}x_j(t)}$ found using \"leaky integrator\"<br>\n",
    "    $a(t+h) ~= a(t) + h\\frac{da(t)}{dt}$ found using \"Euler's Forward Method\"<br>\n",
    "    $a(t+h) ~= a(t) + h*(-(1/\\tau) * a(t) + \\sum^{N}_{i=1}{w_{ij}x_j(t)})$<br>\n",
    "    I guess we're also willing to assume that $a(0) == 0$<br>\n",
    "    TODO: look further into this\n",
    "</p>\n",
    "<hr>\n",
    "\n",
    "<h2>Using output of neuron for time $t+h$</h2>\n",
    "<p>\n",
    "    $y_i(t) = \\Phi(a_i(t) - \\theta_i)$ where $\\Phi$ is the activation function and $\\theta_i$ is the bias of the nueron<br>\n",
    "    So we replace time $t$ with time $t+h$<br>\n",
    "    $y_i(t+h) = \\Phi(a_i(t+h) - \\theta_i)$ as you can see the $a(t+h)$ we defined above if now found here<br>\n",
    "    So we can just fill in the defintion we found above<br>\n",
    "    $a(t+h) ~= a(t) + h*(-(1/\\tau) * a(t) + \\sum^{N}_{i=1}{w_{ij}x_j(t)})$<br>\n",
    "    $y_i(t+h) = \\Phi(... - \\theta_i)$ where ... is the above line\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Takes the rate of 'loss' of a line, it's current value, and its input and finds an approx of the slope\n",
    "def leaky_integrator(A, x, C):\n",
    "    return (-A) * x + C\n",
    "\n",
    "#Returns an approximation of the value of a lone after time \"time_step\"\n",
    "def forward_euler_method(time_step, slope, value):\n",
    "    return value + time_step * slope\n",
    "\n",
    "class HopfieldRecurrentNeuron(object):\n",
    "    def __init__(self, input_count, tau=1.0, bias=0.0):\n",
    "        self.tau = tau #it's used later as 1/tau so higher values of tau causer more leakage\n",
    "        self.weights = [random.random() for i in range(input_count)]\n",
    "        self.prev_activation = 0 #assumed a(0) = 0\n",
    "        self.bias = bias\n",
    "    \n",
    "    @property\n",
    "    def tau(self):\n",
    "        return self.__tau\n",
    "    \n",
    "    @tau.setter\n",
    "    def tau(self, tau_val):\n",
    "        self.__tau = tau_val\n",
    "        self.leak_rate = 1 / tau_val #defines it upon updating the bias rather than each time it needs to be used\n",
    "    \n",
    "    def get_output(self, input_values, time_step=0.0):\n",
    "        input_sum = sum([self.weights[i] * input_values[i] for i in range(len(input_values))])\n",
    "        \n",
    "        activation_slope_approx = leaky_integrator(self.leak_rate, self.prev_activation, input_sum)\n",
    "        activation = forward_euler_method(time_step, activation_slope_approx, self.prev_activation)\n",
    "        \n",
    "        output = sigmoid(activation - self.bias)\n",
    "        \n",
    "        self.prev_activation = activation\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "neuron = HopfieldRecurrentNeuron(1, 3, 0.0)\n",
    "for i in range(100):\n",
    "    print(neuron.get_output([0], 1))\n",
    "print(sigmoid(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = HopfieldRecurrentNeuron(1, 2.8, 2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f6604299400>]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#this is the graph the neural activation as time passes, when an input is only given as an instantenous input at t=0\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "#This makes it look more like the graph from the book\n",
    "x.append(0)\n",
    "y.append(0)\n",
    "\n",
    "x.append(0)\n",
    "n.get_output([1], time_step=1)\n",
    "y.append(n.prev_activation)\n",
    "for i in range(15):\n",
    "    #print(n.test_input([0], time_step=1))\n",
    "    x.append(i+1)\n",
    "    n.get_output([0], time_step=1)\n",
    "    y.append(n.prev_activation)\n",
    "    \n",
    "plt.plot(x,y)\n",
    "#It approches 0 as the value goes on because the leak causes a slow degradation as no input is added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CTRNeuralNetwork(object):\n",
    "    def __init__(self, layer_size_ls):\n",
    "        #Create layers with inputs the size of the previous layers output count\n",
    "        self.layers = []\n",
    "        for i in range(1, len(layer_size_ls)):\n",
    "            layer_size = layer_size_ls[i]\n",
    "            prev_layer_size = layer_size_ls[i-1]\n",
    "            \n",
    "            #Each layer is represented by a list of neurons of a size with inputs large enough for the previous layer\n",
    "            self.layers.append([HopfieldRecurrentNeuron(prev_layer_size) for i in range(layer_size)]) \n",
    "    \n",
    "    def advance(self, inputs, time_step):\n",
    "        layer_output = inputs\n",
    "        for layer in self.layers:\n",
    "            layer_output = [neuron.get_output(layer_output, time_step=time_step) for neuron in layer]\n",
    "        return layer_output\n",
    "    \n",
    "    @staticmethod\n",
    "    def network_from_genome(genome, layer_size_ls):\n",
    "        #we're only going to evolve the network parameterers\n",
    "        #each set of 3 values in the genome is a neuron\n",
    "        n = CTRNeuralNetwork(layer_size_ls)\n",
    "        k = 0\n",
    "        for i in range(len(n.layers)):\n",
    "            layer = n.layers[i]\n",
    "            for j in range(len(layer)):\n",
    "                neuron = layer[j]\n",
    "                \n",
    "                neuron.bias = genome[k+0]\n",
    "                neuron.tau = genome[k+1]\n",
    "                neuron.weights = genome[k+2: k+2+len(neuron.weights)]\n",
    "                \n",
    "                \n",
    "                k += len(neuron.weights) + 2\n",
    "        \n",
    "        return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def print_best_performing(pop):\\n    hf = pop.highest_fitness_individual\\n    n = CTRNeuralNetwork.network_from_genome(hf.genotype, hf.layer_size_ls)\\n    print(n.advance([0,0,1,0,0,0], 0.1))    \\n    \\npop = TournamentPopulation(NetworkIndividual, 1000)\\n#pop.run_cycle()\\nprint(pop.highest_fitness_individual)\\nprint(pop.highest_fitness)\\nfor i in tqdm_notebook(range(100000)):\\n    if i % 1000 == 0:\\n        print_best_performing(pop)\\n    pop.run_cycle()\\n    \\nprint(pop.highest_fitness_individual)\\nprint(pop.highest_fitness)\\nprint_best_performing(pop)'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from GeneticAlgorithm import *\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "#make the individual\n",
    "class NetworkIndividual(AbstractLinkedListIndividual):\n",
    "    def __init__(self):\n",
    "        self.layer_size_ls = [6, 5, 6] #All characters of alphabet as input and output\n",
    "        \n",
    "        #Encode neurons as a list of their values\n",
    "        self.genotype = []\n",
    "        for i in range(1, len(self.layer_size_ls)):\n",
    "            prev_layer_size = self.layer_size_ls[i-1]\n",
    "            layer_size = self.layer_size_ls[i]\n",
    "            \n",
    "            for i in range(layer_size):\n",
    "                self.genotype.append(random.random()) #bias\n",
    "                self.genotype.append(random.random() * 50) #tau\n",
    "                self.genotype.extend([random.random() for i in range(prev_layer_size)]) #weights for neuron_i\n",
    "                #Should be -1 + random.random()*2\n",
    "        \n",
    "    def mutate(self, mutation_rate):\n",
    "        for i in range(len(self.genotype)):\n",
    "            if random.random() < mutation_rate:\n",
    "                self.genotype[i] = random.random()\n",
    "    \n",
    "    def fitness(self):\n",
    "        n = CTRNeuralNetwork.network_from_genome(self.genotype, self.layer_size_ls)\n",
    "        sequence = [0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0]\n",
    "        max_val = max(sequence)\n",
    "        encoded_sequence = [[(j is value) for j in range(max_val+1)] for value in sequence]\n",
    "        \n",
    "        total_error = 0.0\n",
    "        for i in range(len(encoded_sequence)-1):\n",
    "            this_value = encoded_sequence[i]\n",
    "            next_value = encoded_sequence[i+1]\n",
    "            \n",
    "            output = n.advance(this_value, 0.0000001)\n",
    "            #Squared error\n",
    "            \n",
    "            total_error += sum((next_value[i]-output[i])**2 for i in range(len(output)))\n",
    "        \n",
    "        return -total_error #Uses a negative because this network is built to optimize for higher values\n",
    "            \n",
    "            \n",
    "    \n",
    "\"\"\"def print_best_performing(pop):\n",
    "    hf = pop.highest_fitness_individual\n",
    "    n = CTRNeuralNetwork.network_from_genome(hf.genotype, hf.layer_size_ls)\n",
    "    print(n.advance([0,0,1,0,0,0], 0.1))    \n",
    "    \n",
    "pop = TournamentPopulation(NetworkIndividual, 1000)\n",
    "#pop.run_cycle()\n",
    "print(pop.highest_fitness_individual)\n",
    "print(pop.highest_fitness)\n",
    "for i in tqdm_notebook(range(100000)):\n",
    "    if i % 1000 == 0:\n",
    "        print_best_performing(pop)\n",
    "    pop.run_cycle()\n",
    "    \n",
    "print(pop.highest_fitness_individual)\n",
    "print(pop.highest_fitness)\n",
    "print_best_performing(pop)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-85-81862aa57aa3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenotype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'hf' is not defined"
     ]
    }
   ],
   "source": [
    "print(hf.genotype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3122191419848097\n",
      "-0.8974459244211797\n",
      "-0.42039929738767645\n",
      "-0.1283477663954602\n",
      "-0.5226340497459268\n",
      "0.4320927636193508\n",
      "0.33117694702578593\n",
      "-0.9769233407229452\n",
      "-0.7722902843288053\n",
      "-0.017723772742728183\n",
      "-0.7606029162851151\n",
      "0.869953178193416\n",
      "0.4462728035312773\n",
      "-0.5745037768614616\n",
      "0.4648293303490101\n",
      "0.252084862571867\n",
      "-0.9304779137802393\n",
      "-0.4149289141975836\n",
      "-0.6084998168529594\n",
      "0.5993832472209306\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(-1 + random.random()*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.42436377623451826]\n",
      "[0.42436377623451826]\n",
      "[0.42436377623451826]\n",
      "[0.42436377623451826]\n",
      "[0.42436377623451826]\n",
      "[0.4365732064532725]\n",
      "[0.4365732064532725]\n",
      "[0.42436377623451826]\n",
      "[0.42436377623451826]\n",
      "[0.42436377623451826]\n",
      "[0.42436377623451826]\n",
      "[0.42436377623451826]\n"
     ]
    }
   ],
   "source": [
    "n = CTRNeuralNetwork([2, 2, 1])\n",
    "n.layers[0][0].weights = [1, 1] #left hidden\n",
    "n.layers[0][0].bias = 0.5\n",
    "\n",
    "n.layers[0][1].weights = [-1, -1] #right hidden\n",
    "n.layers[0][1].bias = -1.5\n",
    "\n",
    "n.layers[1][0].weights = [1, 1] #output\n",
    "n.layers[1][0].bias = 1.5\n",
    "\n",
    "print(n.advance([0,0], 1))\n",
    "print(n.advance([0,0], 1))\n",
    "print(n.advance([0,0], 1))\n",
    "print(n.advance([0,0], 1))\n",
    "print(n.advance([0,0], 1))\n",
    "print(n.advance([0,1], 1))\n",
    "print(n.advance([1,0], 1))\n",
    "print(n.advance([1,1], 1))\n",
    "print(n.advance([1,1], 1))\n",
    "print(n.advance([1,1], 1))\n",
    "print(n.advance([1,1], 1))\n",
    "print(n.advance([1,1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
